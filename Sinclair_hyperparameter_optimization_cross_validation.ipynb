{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from xgboost import XGBRegressor\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation functions\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_log_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrangle function\n",
    "\n",
    "def wrangle(X):\n",
    "    X = X.copy()\n",
    "    \n",
    "    # Engineer date features\n",
    "    X['quote_date'] = pd.to_datetime(X['quote_date'], infer_datetime_format=True)\n",
    "    X['quote_date_year'] = X['quote_date'].dt.year\n",
    "    X['quote_date_month'] = X['quote_date'].dt.month\n",
    "    X = X.drop(columns='quote_date')\n",
    "    \n",
    "    # Merge tube data\n",
    "    tube = pd.read_csv('competition_data/tube.csv')\n",
    "    X = X.merge(tube, how='left')\n",
    "    \n",
    "    # Engineer features from bill_of_materials\n",
    "    materials = pd.read_csv('competition_data/bill_of_materials.csv')\n",
    "    \n",
    "    materials['components_total'] = (materials['quantity_1'].fillna(0) + \n",
    "                                     materials['quantity_2'].fillna(0) + \n",
    "                                     materials['quantity_3'].fillna(0) + \n",
    "                                     materials['quantity_4'].fillna(0) + \n",
    "                                     materials['quantity_5'].fillna(0) + \n",
    "                                     materials['quantity_6'].fillna(0) + \n",
    "                                     materials['quantity_7'].fillna(0) + \n",
    "                                     materials['quantity_8'].fillna(0))\n",
    "\n",
    "    materials['components_distinct'] = (materials['component_id_1'].notnull().astype(int) + \n",
    "                                        materials['component_id_2'].notnull().astype(int) + \n",
    "                                        materials['component_id_3'].notnull().astype(int) + \n",
    "                                        materials['component_id_4'].notnull().astype(int) + \n",
    "                                        materials['component_id_5'].notnull().astype(int) + \n",
    "                                        materials['component_id_6'].notnull().astype(int) + \n",
    "                                        materials['component_id_7'].notnull().astype(int) + \n",
    "                                        materials['component_id_8'].notnull().astype(int))\n",
    "    \n",
    "    # Engineer features from components and bill_of_materials\n",
    "    components = pd.read_csv('competition_data/components.csv')\n",
    "    \n",
    "    # create dictionary to map component_id to component_id_type\n",
    "    component_dict = components[['component_id', 'component_type_id']].set_index('component_id').to_dict(orient='dict')\n",
    "    component_dict = component_dict['component_type_id']\n",
    "    \n",
    "    # use the dictionary to replace component_id in bill_of_materials with component_id_type\n",
    "    materials_type = materials.replace(component_dict)\n",
    "    \n",
    "    # create a function to return the tally of components with a specified component type in a row\n",
    "    def count(row):\n",
    "        tally=0\n",
    "        for num in range(1,6):\n",
    "            name = 'component_id_' + str(num)\n",
    "            quantity = 'quantity_' + str(num)\n",
    "            if row[name]==item:\n",
    "                tally += row[quantity]\n",
    "            return tally\n",
    "    \n",
    "    # get a list of unique component types\n",
    "    component_type_list = components.component_type_id.unique().tolist()\n",
    "    \n",
    "    # iterate over the list of component types and apply the function to \n",
    "    # create a feature with the row tallies\n",
    "    for item in component_type_list:\n",
    "        materials_type[item] = materials_type.apply(count, axis=1)\n",
    "    \n",
    "    # Merge selected features from bill_of_materials\n",
    "    # Just use the first component_id, ignore the others for now!\n",
    "    features = ['tube_assembly_id', 'component_id_1', 'components_total', 'components_distinct',\n",
    "                'OTHER', 'CP-024', 'CP-026', 'CP-028', 'CP-014', \n",
    "                'CP-018', 'CP-001', 'CP-008', 'CP-009', 'CP-002', \n",
    "                'CP-010', 'CP-021', 'CP-011', 'CP-015', 'CP-027',\n",
    "                'CP-003', 'CP-004', 'CP-005', 'CP-019', 'CP-025', \n",
    "                'CP-006', 'CP-016', 'CP-020', 'CP-012', 'CP-022', \n",
    "                'CP-007', 'CP-017', 'CP-023', 'CP-029']\n",
    "    X = X.merge(materials_type[features], how='left')\n",
    "    \n",
    "    # Get component_type_id (has lower cardinality than component_id)\n",
    "    components = pd.read_csv('competition_data/components.csv')\n",
    "    components = components.rename(columns={'component_id': 'component_id_1'})\n",
    "    features = ['component_id_1', 'component_type_id']\n",
    "    X = X.merge(components[features], how='left')\n",
    "    \n",
    "    # Count the number of specs for the tube assembly\n",
    "    specs = pd.read_csv('competition_data/specs.csv')\n",
    "    specs['specs_total'] = specs.drop(columns=['tube_assembly_id']).count(axis=1)\n",
    "    features = ['tube_assembly_id', 'specs_total', 'spec1']\n",
    "    X = X.merge(specs[features], how='left')\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30213, 8), (30235, 8))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data\n",
    "train = pd.read_csv('competition_data/train_set.csv')\n",
    "test = pd.read_csv('competition_data/test_set.csv')\n",
    "\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrangle train, validation, and test sets\n",
    "train = wrangle(train)\n",
    "test = wrangle(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrange X matrix and y vector (log-transformed)\n",
    "target = 'cost'\n",
    "X_train = train.drop(columns=target)\n",
    "X_test = test.drop(columns='id')\n",
    "y_train = train[target]\n",
    "y_train_log = np.log1p(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction function\n",
    "def generate_submission(estimator, X_test_param, filename):\n",
    "    y_pred_log = estimator.predict(X_test_param)\n",
    "    y_pred = np.expm1(y_pred_log)  # Convert from log-dollars to dollars\n",
    "    submission = pd.read_csv('sample_submission.csv')\n",
    "    submission['cost'] = y_pred\n",
    "    submission.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now lets do a gradient boosting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = ce.OneHotEncoder()\n",
    "X_train_encoded = encoder.fit_transform(X_train, cols=['material_id', 'supplier'])\n",
    "X_test_encoded = encoder.fit_transform(X_test, cols=['material_id', 'supplier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = ce.OrdinalEncoder()\n",
    "X_train_encoded = encoder.fit_transform(X_train)\n",
    "X_test_encoded = encoder.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_set = [(X_train_encoded, y_train_log),\n",
    "#             (X_val_encoded, y_val_log)]\n",
    "\n",
    "# model = XGBRegressor(n_estimators=2000, n_jobs=-1, eta=0.085, max_depth=6)\n",
    "# model.fit(X_train_encoded, y_train_log, eval_set=eval_set, eval_metric='rmse',\n",
    "#          early_stopping_rounds=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint, uniform\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:  9.8min\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed: 20.3min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed: 29.4min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed: 34.9min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed: 49.6min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 59.6min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed: 67.7min finished\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "groups = train['tube_assembly_id']\n",
    "param_distributions = {\n",
    "    'n_estimators': randint(800, 1000), \n",
    "    'max_depth': [6,7,8],\n",
    "    'learning_rate': [.08, .085, .09, .095, .1, .105, .11, .115, .12] \n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    model, \n",
    "    param_distributions=param_distributions, \n",
    "    n_iter=10, \n",
    "    cv=5, \n",
    "    scoring='neg_mean_squared_error', \n",
    "    verbose=10, \n",
    "    return_train_score=True, \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "search.fit(X_train_encoded, y_train_log, groups=groups);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters {'learning_rate': 0.095, 'max_depth': 6, 'n_estimators': 861}\n",
      "Cross-validation RMSLE 0.30153316046805045\n"
     ]
    }
   ],
   "source": [
    "print('Best hyperparameters', search.best_params_)\n",
    "print('Cross-validation RMSLE', np.sqrt(-search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>256.735391</td>\n",
       "      <td>8.657783</td>\n",
       "      <td>1.071139</td>\n",
       "      <td>0.387696</td>\n",
       "      <td>0.095</td>\n",
       "      <td>6</td>\n",
       "      <td>861</td>\n",
       "      <td>{'learning_rate': 0.095, 'max_depth': 6, 'n_es...</td>\n",
       "      <td>-0.091960</td>\n",
       "      <td>-0.067823</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.090922</td>\n",
       "      <td>0.018437</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.006405</td>\n",
       "      <td>-0.006211</td>\n",
       "      <td>-0.005512</td>\n",
       "      <td>-0.003662</td>\n",
       "      <td>-0.006640</td>\n",
       "      <td>-0.005686</td>\n",
       "      <td>0.001080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>265.346564</td>\n",
       "      <td>12.202934</td>\n",
       "      <td>2.852531</td>\n",
       "      <td>0.534164</td>\n",
       "      <td>0.115</td>\n",
       "      <td>7</td>\n",
       "      <td>828</td>\n",
       "      <td>{'learning_rate': 0.115, 'max_depth': 7, 'n_es...</td>\n",
       "      <td>-0.085974</td>\n",
       "      <td>-0.071797</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.091376</td>\n",
       "      <td>0.018611</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.001857</td>\n",
       "      <td>-0.002051</td>\n",
       "      <td>-0.001498</td>\n",
       "      <td>-0.001096</td>\n",
       "      <td>-0.002090</td>\n",
       "      <td>-0.001718</td>\n",
       "      <td>0.000375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>251.339458</td>\n",
       "      <td>6.950165</td>\n",
       "      <td>1.300170</td>\n",
       "      <td>0.322335</td>\n",
       "      <td>0.085</td>\n",
       "      <td>6</td>\n",
       "      <td>937</td>\n",
       "      <td>{'learning_rate': 0.085, 'max_depth': 6, 'n_es...</td>\n",
       "      <td>-0.095094</td>\n",
       "      <td>-0.068905</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.091993</td>\n",
       "      <td>0.017300</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.006748</td>\n",
       "      <td>-0.006425</td>\n",
       "      <td>-0.005929</td>\n",
       "      <td>-0.004069</td>\n",
       "      <td>-0.006758</td>\n",
       "      <td>-0.005986</td>\n",
       "      <td>0.001005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>228.017617</td>\n",
       "      <td>8.407867</td>\n",
       "      <td>0.812825</td>\n",
       "      <td>0.123257</td>\n",
       "      <td>0.105</td>\n",
       "      <td>6</td>\n",
       "      <td>817</td>\n",
       "      <td>{'learning_rate': 0.105, 'max_depth': 6, 'n_es...</td>\n",
       "      <td>-0.099423</td>\n",
       "      <td>-0.068314</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.093957</td>\n",
       "      <td>0.018628</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.005858</td>\n",
       "      <td>-0.005659</td>\n",
       "      <td>-0.005378</td>\n",
       "      <td>-0.003713</td>\n",
       "      <td>-0.006022</td>\n",
       "      <td>-0.005326</td>\n",
       "      <td>0.000835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>245.289942</td>\n",
       "      <td>48.315894</td>\n",
       "      <td>1.098830</td>\n",
       "      <td>0.232231</td>\n",
       "      <td>0.09</td>\n",
       "      <td>7</td>\n",
       "      <td>956</td>\n",
       "      <td>{'learning_rate': 0.09, 'max_depth': 7, 'n_est...</td>\n",
       "      <td>-0.103726</td>\n",
       "      <td>-0.068700</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.095230</td>\n",
       "      <td>0.021781</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.002304</td>\n",
       "      <td>-0.002364</td>\n",
       "      <td>-0.001991</td>\n",
       "      <td>-0.001257</td>\n",
       "      <td>-0.002507</td>\n",
       "      <td>-0.002085</td>\n",
       "      <td>0.000447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>449.778756</td>\n",
       "      <td>43.845482</td>\n",
       "      <td>7.917541</td>\n",
       "      <td>0.777294</td>\n",
       "      <td>0.085</td>\n",
       "      <td>8</td>\n",
       "      <td>952</td>\n",
       "      <td>{'learning_rate': 0.085, 'max_depth': 8, 'n_es...</td>\n",
       "      <td>-0.125415</td>\n",
       "      <td>-0.067273</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.098107</td>\n",
       "      <td>0.024193</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.000986</td>\n",
       "      <td>-0.000927</td>\n",
       "      <td>-0.000795</td>\n",
       "      <td>-0.000479</td>\n",
       "      <td>-0.001015</td>\n",
       "      <td>-0.000840</td>\n",
       "      <td>0.000196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>338.902435</td>\n",
       "      <td>5.834281</td>\n",
       "      <td>2.701644</td>\n",
       "      <td>0.600175</td>\n",
       "      <td>0.11</td>\n",
       "      <td>7</td>\n",
       "      <td>997</td>\n",
       "      <td>{'learning_rate': 0.11, 'max_depth': 7, 'n_est...</td>\n",
       "      <td>-0.122623</td>\n",
       "      <td>-0.069824</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.099016</td>\n",
       "      <td>0.022039</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.001513</td>\n",
       "      <td>-0.001443</td>\n",
       "      <td>-0.001174</td>\n",
       "      <td>-0.000837</td>\n",
       "      <td>-0.001517</td>\n",
       "      <td>-0.001297</td>\n",
       "      <td>0.000262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>316.550304</td>\n",
       "      <td>17.831761</td>\n",
       "      <td>3.826401</td>\n",
       "      <td>0.969465</td>\n",
       "      <td>0.105</td>\n",
       "      <td>8</td>\n",
       "      <td>899</td>\n",
       "      <td>{'learning_rate': 0.105, 'max_depth': 8, 'n_es...</td>\n",
       "      <td>-0.123425</td>\n",
       "      <td>-0.069869</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.099054</td>\n",
       "      <td>0.022762</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.000619</td>\n",
       "      <td>-0.000723</td>\n",
       "      <td>-0.000588</td>\n",
       "      <td>-0.000328</td>\n",
       "      <td>-0.000708</td>\n",
       "      <td>-0.000593</td>\n",
       "      <td>0.000142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>314.887824</td>\n",
       "      <td>2.123291</td>\n",
       "      <td>2.298544</td>\n",
       "      <td>0.298158</td>\n",
       "      <td>0.11</td>\n",
       "      <td>8</td>\n",
       "      <td>897</td>\n",
       "      <td>{'learning_rate': 0.11, 'max_depth': 8, 'n_est...</td>\n",
       "      <td>-0.121543</td>\n",
       "      <td>-0.068597</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.100620</td>\n",
       "      <td>0.024269</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.000568</td>\n",
       "      <td>-0.000619</td>\n",
       "      <td>-0.000471</td>\n",
       "      <td>-0.000259</td>\n",
       "      <td>-0.000586</td>\n",
       "      <td>-0.000501</td>\n",
       "      <td>0.000130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>379.725099</td>\n",
       "      <td>51.441597</td>\n",
       "      <td>4.322969</td>\n",
       "      <td>2.439842</td>\n",
       "      <td>0.115</td>\n",
       "      <td>8</td>\n",
       "      <td>839</td>\n",
       "      <td>{'learning_rate': 0.115, 'max_depth': 8, 'n_es...</td>\n",
       "      <td>-0.124219</td>\n",
       "      <td>-0.071470</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.101469</td>\n",
       "      <td>0.022532</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.000619</td>\n",
       "      <td>-0.000557</td>\n",
       "      <td>-0.000540</td>\n",
       "      <td>-0.000311</td>\n",
       "      <td>-0.000613</td>\n",
       "      <td>-0.000528</td>\n",
       "      <td>0.000113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "3     256.735391      8.657783         1.071139        0.387696   \n",
       "0     265.346564     12.202934         2.852531        0.534164   \n",
       "4     251.339458      6.950165         1.300170        0.322335   \n",
       "7     228.017617      8.407867         0.812825        0.123257   \n",
       "9     245.289942     48.315894         1.098830        0.232231   \n",
       "1     449.778756     43.845482         7.917541        0.777294   \n",
       "6     338.902435      5.834281         2.701644        0.600175   \n",
       "5     316.550304     17.831761         3.826401        0.969465   \n",
       "8     314.887824      2.123291         2.298544        0.298158   \n",
       "2     379.725099     51.441597         4.322969        2.439842   \n",
       "\n",
       "  param_learning_rate param_max_depth param_n_estimators  \\\n",
       "3               0.095               6                861   \n",
       "0               0.115               7                828   \n",
       "4               0.085               6                937   \n",
       "7               0.105               6                817   \n",
       "9                0.09               7                956   \n",
       "1               0.085               8                952   \n",
       "6                0.11               7                997   \n",
       "5               0.105               8                899   \n",
       "8                0.11               8                897   \n",
       "2               0.115               8                839   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "3  {'learning_rate': 0.095, 'max_depth': 6, 'n_es...          -0.091960   \n",
       "0  {'learning_rate': 0.115, 'max_depth': 7, 'n_es...          -0.085974   \n",
       "4  {'learning_rate': 0.085, 'max_depth': 6, 'n_es...          -0.095094   \n",
       "7  {'learning_rate': 0.105, 'max_depth': 6, 'n_es...          -0.099423   \n",
       "9  {'learning_rate': 0.09, 'max_depth': 7, 'n_est...          -0.103726   \n",
       "1  {'learning_rate': 0.085, 'max_depth': 8, 'n_es...          -0.125415   \n",
       "6  {'learning_rate': 0.11, 'max_depth': 7, 'n_est...          -0.122623   \n",
       "5  {'learning_rate': 0.105, 'max_depth': 8, 'n_es...          -0.123425   \n",
       "8  {'learning_rate': 0.11, 'max_depth': 8, 'n_est...          -0.121543   \n",
       "2  {'learning_rate': 0.115, 'max_depth': 8, 'n_es...          -0.124219   \n",
       "\n",
       "   split1_test_score       ...         mean_test_score  std_test_score  \\\n",
       "3          -0.067823       ...               -0.090922        0.018437   \n",
       "0          -0.071797       ...               -0.091376        0.018611   \n",
       "4          -0.068905       ...               -0.091993        0.017300   \n",
       "7          -0.068314       ...               -0.093957        0.018628   \n",
       "9          -0.068700       ...               -0.095230        0.021781   \n",
       "1          -0.067273       ...               -0.098107        0.024193   \n",
       "6          -0.069824       ...               -0.099016        0.022039   \n",
       "5          -0.069869       ...               -0.099054        0.022762   \n",
       "8          -0.068597       ...               -0.100620        0.024269   \n",
       "2          -0.071470       ...               -0.101469        0.022532   \n",
       "\n",
       "   rank_test_score  split0_train_score  split1_train_score  \\\n",
       "3                1           -0.006405           -0.006211   \n",
       "0                2           -0.001857           -0.002051   \n",
       "4                3           -0.006748           -0.006425   \n",
       "7                4           -0.005858           -0.005659   \n",
       "9                5           -0.002304           -0.002364   \n",
       "1                6           -0.000986           -0.000927   \n",
       "6                7           -0.001513           -0.001443   \n",
       "5                8           -0.000619           -0.000723   \n",
       "8                9           -0.000568           -0.000619   \n",
       "2               10           -0.000619           -0.000557   \n",
       "\n",
       "   split2_train_score  split3_train_score  split4_train_score  \\\n",
       "3           -0.005512           -0.003662           -0.006640   \n",
       "0           -0.001498           -0.001096           -0.002090   \n",
       "4           -0.005929           -0.004069           -0.006758   \n",
       "7           -0.005378           -0.003713           -0.006022   \n",
       "9           -0.001991           -0.001257           -0.002507   \n",
       "1           -0.000795           -0.000479           -0.001015   \n",
       "6           -0.001174           -0.000837           -0.001517   \n",
       "5           -0.000588           -0.000328           -0.000708   \n",
       "8           -0.000471           -0.000259           -0.000586   \n",
       "2           -0.000540           -0.000311           -0.000613   \n",
       "\n",
       "   mean_train_score  std_train_score  \n",
       "3         -0.005686         0.001080  \n",
       "0         -0.001718         0.000375  \n",
       "4         -0.005986         0.001005  \n",
       "7         -0.005326         0.000835  \n",
       "9         -0.002085         0.000447  \n",
       "1         -0.000840         0.000196  \n",
       "6         -0.001297         0.000262  \n",
       "5         -0.000593         0.000142  \n",
       "8         -0.000501         0.000130  \n",
       "2         -0.000528         0.000113  \n",
       "\n",
       "[10 rows x 23 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(search.cv_results_).sort_values(by='rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = search.best_estimator_\n",
    "y_pred_log = pipeline.predict(X_test_encoded)\n",
    "y_pred = np.expm1(y_pred_log)  # Convert from log-dollars to dollars\n",
    "submission = pd.read_csv('sample_submission.csv')\n",
    "submission['cost'] = y_pred\n",
    "submission.to_csv('submission-40.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
