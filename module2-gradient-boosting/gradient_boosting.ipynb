{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "competition_data/comp_threaded.csv (194, 32)\n",
      "competition_data/comp_adaptor.csv (25, 20)\n",
      "competition_data/tube_end_form.csv (27, 2)\n",
      "competition_data/comp_straight.csv (361, 12)\n",
      "competition_data/comp_tee.csv (4, 14)\n",
      "competition_data/comp_boss.csv (147, 15)\n",
      "competition_data/components.csv (2048, 3)\n",
      "competition_data/comp_float.csv (16, 7)\n",
      "competition_data/bill_of_materials.csv (21198, 17)\n",
      "competition_data/comp_elbow.csv (178, 16)\n",
      "competition_data/type_connection.csv (14, 2)\n",
      "competition_data/train_set.csv (30213, 8)\n",
      "competition_data/comp_sleeve.csv (50, 10)\n",
      "competition_data/test_set.csv (30235, 8)\n",
      "competition_data/tube.csv (21198, 16)\n",
      "competition_data/comp_hfl.csv (6, 9)\n",
      "competition_data/type_end_form.csv (8, 2)\n",
      "competition_data/comp_other.csv (1001, 3)\n",
      "competition_data/type_component.csv (29, 2)\n",
      "competition_data/specs.csv (21198, 11)\n",
      "competition_data/comp_nut.csv (65, 11)\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "\n",
    "for path in glob('competition_data/*.csv'):\n",
    "    df = pd.read_csv(path)\n",
    "    print(path, df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('competition_data/train_set.csv')\n",
    "test = pd.read_csv('competition_data/test_set.csv')\n",
    "tube = pd.read_csv('competition_data/tube.csv')\n",
    "mats = pd.read_csv('competition_data/bill_of_materials.csv')\n",
    "comps = pd.read_csv('competition_data/components.csv')\n",
    "specs = pd.read_csv('competition_data/specs.csv')\n",
    "end_form = pd.read_csv('competition_data/tube_end_form.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging tube df with end_form df\n",
    "tube = tube.merge(end_form,how='left',left_on='end_a',right_on='end_form_id').merge(end_form,how='left',left_on='end_x',right_on='end_form_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicate ids\n",
    "tube = tube.drop(['end_form_id_x','end_form_id_y'],axis=1)\n",
    "# rename forming columns to match end_a and end_x\n",
    "tube = tube.rename({'forming_x':'forming_a','forming_y':'forming_x'},axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### merging comps onto mats.\n",
    "We are only going to use the first component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging comps on mats but only on the first component\n",
    "mats = mats.merge(comps,left_on='component_id_1',right_on='component_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping redundant columns\n",
    "mats = mats.drop(['component_id','component_type_id'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = train.merge(tube, left_on='tube_assembly_id',right_on='tube_assembly_id',how='left')\n",
    "test = test.merge(tube, left_on='tube_assembly_id',right_on='tube_assembly_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.merge(mats,left_on='tube_assembly_id',right_on='tube_assembly_id',how='left')\n",
    "test = test.merge(mats,left_on='tube_assembly_id',right_on='tube_assembly_id',how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform skewed cols\n",
    "def transform_skewed_cols(df, skew_level=4):\n",
    "    skew_cols = list(train.skew()[train.skew() > skew_level].index)\n",
    "    for col in skew_cols:\n",
    "        df[col] = np.log1p(df[col])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in log1p\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "train = transform_skewed_cols(train)\n",
    "test = transform_skewed_cols(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove quote date and replace by year and month cols\n",
    "def convert_add_dates(df):\n",
    "    df['quote_date'] = pd.to_datetime(df['quote_date'],infer_datetime_format=True)\n",
    "    df['month'] = df['quote_date'].dt.month\n",
    "    df['year'] = df['quote_date'].dt.year\n",
    "    df = df.drop('quote_date',axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test = convert_add_dates(test)\n",
    "train = convert_add_dates(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM for missing material Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_nas = train[train['material_id'].isna()]\n",
    "test_nas = test[test['material_id'].isna()]\n",
    "train_not_null = train[~train['material_id'].isna()]\n",
    "test_not_null = test[~test['material_id'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:4034: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  downcast=downcast, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "train_not_null.fillna(0,inplace=True)\n",
    "test_not_null.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'material_id'\n",
    "features = list(train.columns)\n",
    "features.remove('material_id')\n",
    "features.remove('cost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_not_null[features]\n",
    "y = train_not_null[target]\n",
    "X_test = test_not_null[features]\n",
    "y_test = test_not_null[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_cols = list(X.describe(exclude='number').columns)\n",
    "encoder = ce.OrdinalEncoder(cols=encode_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_encode = encoder.fit_transform(X)\n",
    "X_test_encode = encoder.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=100,max_depth=20,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=20, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_encode,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9931630202774814"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_encode,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8014595621313606"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test_encode, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets input the missing values on our null set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nas = train_nas[features].fillna(0)\n",
    "test_nas = test_nas[features].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_preds = model.predict(encoder.transform(test_nas))\n",
    "train_preds = model.predict(encoder.transform(train_nas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_nas['material_id'] = test_preds\n",
    "train_nas['material_id'] = train_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "#putting predictions back into test and train\n",
    "test = pd.concat([test_nas,test.loc[~test['material_id'].isna()]])\n",
    "train = pd.concat([train_nas,train.loc[~train['material_id'].isna()]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.81'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgboost.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.fillna(0)\n",
    "train = train.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test splitting based on tube id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tubes = train['tube_assembly_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tubes, val_tubes = train_test_split(unique_tubes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "set(train_tubes) & set(val_tubes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.loc[train['tube_assembly_id'].isin(train_tubes)]\n",
    "X_val = train.loc[train['tube_assembly_id'].isin(val_tubes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# drop tube_id\n",
    "X_train = X_train.drop('tube_assembly_id',axis=1)\n",
    "X_val = X_val.drop('tube_assembly_id',axis=1)\n",
    "test = test.drop('tube_assembly_id',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define ordinal and one hot columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "card = X_train.describe(exclude='number').T.sort_values(by='unique')\n",
    "numerics = X_train.describe()\n",
    "numerics = list(numerics.columns)\n",
    "numerics.remove('cost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hot_encode_cols = list(card.loc[card['unique'] < 150].index)\n",
    "ordinal_encode_cols = list(card.loc[card['unique'] >= 150].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline =  make_pipeline(ce.OrdinalEncoder(cols=ordinal_encode_cols),\n",
    "                   ce.OneHotEncoder(cols=hot_encode_cols,use_cat_names=True),\n",
    "                                   XGBRegressor(n_estimators=100, n_jobs=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### feature defining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'numerics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4667c56da33c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cost'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumerics\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhot_encode_cols\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mordinal_encode_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'numerics' is not defined"
     ]
    }
   ],
   "source": [
    "target = 'cost'\n",
    "features = numerics + hot_encode_cols + ordinal_encode_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_train[features],X_train[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
